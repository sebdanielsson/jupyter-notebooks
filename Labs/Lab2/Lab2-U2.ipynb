{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "469aee76",
   "metadata": {},
   "source": [
    "# GIK2FB - Labb 2 - Uppgift 2\n",
    "\n",
    "## Data set:\n",
    "\n",
    "[Wireless Indoor Localization Data Set](https://archive.ics.uci.edu/ml/datasets/Wireless+Indoor+Localization)\n",
    "\n",
    "## Abstract\n",
    "\n",
    "Collected in indoor space by observing signal strengths of seven WiFi signals visible on a smartphone. The decision variable is one of the four rooms.\n",
    "\n",
    "## Data Set Information:\n",
    "\n",
    "Collected to perform experimentation on how wifi signal strengths can be used to determine one of the indoor locations.\n",
    "\n",
    "## Attribute Information:\n",
    "\n",
    "Each attribute is wifi signal strength observed on smartphone.\n",
    "\n",
    "## Credits\n",
    "\n",
    "1. Rajen Bhatt, 'Fuzzy-Rough Approaches for Pattern Classification: Hybrid measures, Mathematical analysis, Feature selection algorithms, Decision tree algorithms, Neural learning, and Applications', Amazon Books \n",
    "2. Jayant G Rohra, Boominathan Perumal, Swathi Jamjala Narayanan, Priya Thakur, and Rajen B Bhatt, 'User Localization in an Indoor Environment Using Fuzzy Hybrid of Particle Swarm Optimization & Gravitational Search Algorithm with Neural Networks', in Proceedings of Sixth International Conference on Soft Computing for Problem Solving,2017, pp. 286-295."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538104ba",
   "metadata": {},
   "source": [
    "# Import the data set and create dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ec5136-f151-4370-9422-0e8af35bfadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create variables for the columns so that we can easily switch between different data sets with minimal changes\n",
    "columns = ['Agent 1', 'Agent 2', 'Agent 3', 'Agent 4', 'Agent 5', 'Agent 6', 'Agent 7', 'Location']\n",
    "attributes = columns[0:7]\n",
    "target = columns[7]\n",
    "\n",
    "# Import data set and create a data frames\n",
    "dataframe = pd.read_csv('wifi_localization.txt', delim_whitespace=True, header=None, usecols=[*range(0, 8)], names=columns)\n",
    "data = pd.DataFrame.copy(dataframe)\n",
    "data_scaled = pd.DataFrame.copy(dataframe)\n",
    "\n",
    "# Create a scaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalize data in data_scaled\n",
    "data_scaled[attributes] = scaler.fit_transform(data_scaled[attributes])\n",
    "\n",
    "# Convert the array back to a dataframe\n",
    "data_scaled = pd.DataFrame(data_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81bf6d5",
   "metadata": {},
   "source": [
    "# Do some exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7f8bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('Orginal data:')\n",
    "display(round(data.describe(),1))\n",
    "\n",
    "print('Scaled data:')\n",
    "display(round(data_scaled.describe(),1))\n",
    "\n",
    "ax1 = sns.pairplot(data, hue = target)\n",
    "ax1.fig.suptitle(\"Original data\", y=1.02)\n",
    "ax2 = sns.pairplot(data_scaled, hue = target)\n",
    "ax2.fig.suptitle(\"Normalized data\", y=1.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead02fd7",
   "metadata": {},
   "source": [
    "## Single run with original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26191795",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Split data into training and test sets\n",
    "x = data.drop(target, axis = 1)\n",
    "y = data[target]\n",
    "x_training_data, x_test_data, y_training_data, y_test_data = train_test_split(x, y, test_size = 0.25)\n",
    "\n",
    "# Train the decision tree model\n",
    "model = DecisionTreeClassifier(random_state=None)\n",
    "model.fit(x_training_data, y_training_data)\n",
    "\n",
    "# Predict the test set results\n",
    "predictions = model.predict(x_test_data)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3fc9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import tree\n",
    "\n",
    "# Generate a decision tree\n",
    "tree.plot_tree(model)\n",
    "plt.show()\n",
    "\n",
    "# Print the classification report\n",
    "print('\\nClassification report:\\n', classification_report(y_test_data, predictions))\n",
    "\n",
    "# Print the Confusion matrix\n",
    "print('\\nConfustion matrix:\\n', confusion_matrix(y_test_data, predictions))\n",
    "#pd.crosstab(y_test_data, predictions, rownames=['Actual'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40d9c27",
   "metadata": {},
   "source": [
    "## Single run with normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8424d6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Split data into training and test sets\n",
    "x = data.drop(target, axis = 1)\n",
    "y = data[target]\n",
    "x_training_data, x_test_data, y_training_data, y_test_data = train_test_split(x, y, test_size = 0.25)\n",
    "\n",
    "# Train the decision tree model\n",
    "model = DecisionTreeClassifier(random_state=None)\n",
    "model.fit(x_training_data, y_training_data)\n",
    "\n",
    "# Predict the test set results\n",
    "predictions = model.predict(x_test_data)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399f2eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import tree\n",
    "\n",
    "# Generate a decision tree\n",
    "tree.plot_tree(model)\n",
    "plt.show()\n",
    "\n",
    "# Print the classification report\n",
    "print('\\nClassification report:\\n', classification_report(y_test_data, predictions))\n",
    "\n",
    "# Print the Confusion matrix\n",
    "print('\\nConfustion matrix:\\n', confusion_matrix(y_test_data, predictions))\n",
    "#pd.crosstab(y_test_data, predictions, rownames=['Actual'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63900d6",
   "metadata": {},
   "source": [
    "## 100 runs with original data and 75/25 split for training/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126ffbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import tree\n",
    "\n",
    "# Create arrays to store the results\n",
    "accuracy_log = []\n",
    "confusion_matrix_log = []\n",
    "\n",
    "\n",
    "# Do 100 runs\n",
    "for i in range(100):\n",
    "    # Split data into training and test sets\n",
    "    x = data.drop(target, axis = 1)\n",
    "    y = data[target]\n",
    "    x_training_data, x_test_data, y_training_data, y_test_data = train_test_split(x, y, test_size = 0.25)\n",
    "\n",
    "    # Train the decision tree model\n",
    "    model = DecisionTreeClassifier(random_state=None)\n",
    "    model.fit(x_training_data, y_training_data)\n",
    "\n",
    "    # Predict the test set results\n",
    "    predictions = model.predict(x_test_data)\n",
    "    \n",
    "    # Get the classification report\n",
    "    report = classification_report(y_test_data, predictions, output_dict=True, digits=6)\n",
    "\n",
    "    # Save the accuracy for each run\n",
    "    accuracy_log.insert(i, report['accuracy'])\n",
    "\n",
    "    # Save the confusion matrix for each run\n",
    "    confusion_matrix_log.insert(i, confusion_matrix(y_test_data, predictions))\n",
    "\n",
    "\n",
    "# Get index of the highest and second lowest accuracy\n",
    "max_accuracy_index = accuracy_log.index(max(accuracy_log))\n",
    "min_accuracy_index = accuracy_log.index(min(accuracy_log))\n",
    "\n",
    "# Print the highest accuracy and the corresponding confusion matrix for that run\n",
    "print('---Best run---\\nAccuracy:\\n', accuracy_log[max_accuracy_index],'\\n')\n",
    "print('Confusion matrix:\\n', confusion_matrix_log[max_accuracy_index],'\\n\\n')\n",
    "\n",
    "# Print the lowest accuracy and the corresponding confusion matrix for that run\n",
    "print('---Worst run---\\nAccuracy:\\n', accuracy_log[min_accuracy_index],'\\n')\n",
    "print('Confusion matrix:\\n', confusion_matrix_log[min_accuracy_index],'\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e90f643",
   "metadata": {},
   "source": [
    "## 100 runs with original data and 5/95 split for training/test\n",
    "\n",
    "Making minor changes in the split didn't affect the results by a lot so let's take it to the extreme and give the model a very small cut for training. I believe this might, in part, be due to to the large data set compared to the other recommended options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b96a246",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import tree\n",
    "\n",
    "# Create arrays to store the results\n",
    "accuracy_log = []\n",
    "confusion_matrix_log = []\n",
    "\n",
    "\n",
    "# Do 100 runs\n",
    "for i in range(100):\n",
    "    # Split data into training and test sets\n",
    "    x = data.drop(target, axis = 1)\n",
    "    y = data[target]\n",
    "    x_training_data, x_test_data, y_training_data, y_test_data = train_test_split(x, y, test_size = 0.95)\n",
    "\n",
    "    # Train the decision tree model\n",
    "    model = DecisionTreeClassifier(random_state=None)\n",
    "    model.fit(x_training_data, y_training_data)\n",
    "\n",
    "    # Predict the test set results\n",
    "    predictions = model.predict(x_test_data)\n",
    "    \n",
    "    # Get the classification report\n",
    "    report = classification_report(y_test_data, predictions, output_dict=True, digits=6)\n",
    "\n",
    "    # Save the accuracy for each run\n",
    "    accuracy_log.insert(i, report['accuracy'])\n",
    "\n",
    "    # Save the confusion matrix for each run\n",
    "    confusion_matrix_log.insert(i, confusion_matrix(y_test_data, predictions))\n",
    "\n",
    "\n",
    "# Get index of the highest and second lowest accuracy\n",
    "max_accuracy_index = accuracy_log.index(max(accuracy_log))\n",
    "min_accuracy_index = accuracy_log.index(min(accuracy_log))\n",
    "\n",
    "# Print the highest accuracy and the corresponding confusion matrix for that run\n",
    "print('---Best run---\\nAccuracy:\\n', accuracy_log[max_accuracy_index],'\\n')\n",
    "print('Confusion matrix:\\n', confusion_matrix_log[max_accuracy_index],'\\n\\n')\n",
    "\n",
    "# Print the lowest accuracy and the corresponding confusion matrix for that run\n",
    "print('---Worst run---\\nAccuracy:\\n', accuracy_log[min_accuracy_index],'\\n')\n",
    "print('Confusion matrix:\\n', confusion_matrix_log[min_accuracy_index],'\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b5bbe3",
   "metadata": {},
   "source": [
    "## 100 runs with original data and 5/95 split for training/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e78794a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import tree\n",
    "\n",
    "# Create arrays to store the results\n",
    "accuracy_log = []\n",
    "confusion_matrix_log = []\n",
    "\n",
    "\n",
    "# Do 100 runs\n",
    "for i in range(100):\n",
    "    # Split data into training and test sets\n",
    "    x = data_scaled.drop(target, axis = 1)\n",
    "    y = data_scaled[target]\n",
    "    x_training_data, x_test_data, y_training_data, y_test_data = train_test_split(x, y, test_size = 0.25)\n",
    "\n",
    "    # Train the decision tree model\n",
    "    model = DecisionTreeClassifier(random_state=None)\n",
    "    model.fit(x_training_data, y_training_data)\n",
    "\n",
    "    # Predict the test set results\n",
    "    predictions = model.predict(x_test_data)\n",
    "    \n",
    "    # Get the classification report\n",
    "    report = classification_report(y_test_data, predictions, output_dict=True, digits=6)\n",
    "\n",
    "    # Save the accuracy for each run\n",
    "    accuracy_log.insert(i, report['accuracy'])\n",
    "\n",
    "    # Save the confusion matrix for each run\n",
    "    confusion_matrix_log.insert(i, confusion_matrix(y_test_data, predictions))\n",
    "\n",
    "\n",
    "# Get index of the highest and second lowest accuracy\n",
    "max_accuracy_index = accuracy_log.index(max(accuracy_log))\n",
    "min_accuracy_index = accuracy_log.index(min(accuracy_log))\n",
    "\n",
    "# Print the highest accuracy and the corresponding confusion matrix for that run\n",
    "print('---Best run---\\nAccuracy:\\n', accuracy_log[max_accuracy_index],'\\n')\n",
    "print('Confusion matrix:\\n', confusion_matrix_log[max_accuracy_index],'\\n\\n')\n",
    "\n",
    "# Print the lowest accuracy and the corresponding confusion matrix for that run\n",
    "print('---Worst run---\\nAccuracy:\\n', accuracy_log[min_accuracy_index],'\\n')\n",
    "print('Confusion matrix:\\n', confusion_matrix_log[min_accuracy_index],'\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe88b0a",
   "metadata": {},
   "source": [
    "## 100 runs with normalized data and 5/95 split for training/test\n",
    "\n",
    "Making minor changes in the split didn't affect the results by a lot so let's take it to the extreme and give the model a very small cut for training. I believe this might be due to to the large data set compared to the other recommended options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e70fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import tree\n",
    "\n",
    "# Create arrays to store the results\n",
    "accuracy_log = []\n",
    "confusion_matrix_log = []\n",
    "\n",
    "\n",
    "# Do 100 runs\n",
    "for i in range(100):\n",
    "    # Split data into training and test sets\n",
    "    x = data_scaled.drop(target, axis = 1)\n",
    "    y = data_scaled[target]\n",
    "    x_training_data, x_test_data, y_training_data, y_test_data = train_test_split(x, y, test_size = 0.95)\n",
    "\n",
    "    # Train the decision tree model\n",
    "    model = DecisionTreeClassifier(random_state=None)\n",
    "    model.fit(x_training_data, y_training_data)\n",
    "\n",
    "    # Predict the test set results\n",
    "    predictions = model.predict(x_test_data)\n",
    "    \n",
    "    # Get the classification report\n",
    "    report = classification_report(y_test_data, predictions, output_dict=True, digits=6)\n",
    "\n",
    "    # Save the accuracy for each run\n",
    "    accuracy_log.insert(i, report['accuracy'])\n",
    "\n",
    "    # Save the confusion matrix for each run\n",
    "    confusion_matrix_log.insert(i, confusion_matrix(y_test_data, predictions))\n",
    "\n",
    "\n",
    "# Get index of the highest and second lowest accuracy\n",
    "max_accuracy_index = accuracy_log.index(max(accuracy_log))\n",
    "min_accuracy_index = accuracy_log.index(min(accuracy_log))\n",
    "\n",
    "# Print the highest accuracy and the corresponding confusion matrix for that run\n",
    "print('---Best run---\\nAccuracy:\\n', accuracy_log[max_accuracy_index],'\\n')\n",
    "print('Confusion matrix:\\n', confusion_matrix_log[max_accuracy_index],'\\n\\n')\n",
    "\n",
    "# Print the lowest accuracy and the corresponding confusion matrix for that run\n",
    "print('---Worst run---\\nAccuracy:\\n', accuracy_log[min_accuracy_index],'\\n')\n",
    "print('Confusion matrix:\\n', confusion_matrix_log[min_accuracy_index],'\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "73a4deffa37449eec2906a82541729956dc4ede81d351440dc1e5a408dd292eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
