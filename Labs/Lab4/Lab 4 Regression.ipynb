{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GIK2FB Artificial Intelligence HT22\n",
    "\n",
    "## Lab 4: ML - Supervised Regression Learning, Naive Bayes (Probabilistic Classifier)\n",
    "\n",
    "Dalarna University\n",
    "(c) Joonas Pääkkönen, fall 2022\n",
    "\n",
    "### Deadline: Monday Dec 19th, 2022, 23:59 CET time\n",
    "\n",
    "Upload your .ipynb file to Learn. No video, just the .ipynb file. Simply write your code in the .ipynb file and submit it. Do not zip anything, like the datasets, with it.\n",
    "\n",
    "Use Scikit-learn first and foremost, with the help of Pandas, NumPy, SciPy, Matplotlib and Seaborn, if needed. Remember that Pandas dataframes come in very handy in data science.\n",
    "\n",
    "Note: plotting pairplots may take several seconds or even minutes.\n",
    "\n",
    "Make sure that your code runs before submitting.\n",
    "\n",
    "Remember to fill in the information below, i.e., student name(s) and email address(es).\n",
    "\n",
    "### Sebastian Danielsson: model solutions\n",
    "\n",
    "### h21sebda@du.se: model solutions\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1.1: Import Pandas, and download the hungary_chickenpox.csv dataset from\n",
    "https://archive.ics.uci.edu/ml/datasets/Hungarian+Chickenpox+Cases and save the data into a variable called \"chickendata\" with the read.csv() method of the Pandas module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Import data set and create a data frames\n",
    "chickendata = pd.read_csv('hungary_chickenpox.csv', delimiter=',', usecols=[*range(0, 21)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1.2: Print the chickendata dataset by simply writing the variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chickendata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1.3: Use the Pandas describe() method to describe chickendata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chickendata.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1.4: Use Seaborn to plot the pairplot of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "#sns.pairplot(chickendata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1.5: Use the scatterplot() method of Seaborn to plot a scatterplot where the x-coordinates are from the BUDAPEST column and the y-coordinates are from the VAS column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='BUDAPEST', y='VAS', data=chickendata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1.6: Use Scikit-learn to fit a simple linear OLS regression line to the data visualized in Task 1.5. Plot the linear regression line alongside the scatterplot of Task 1.5. Make sure the line and the scatterplot points are in different colors. Note: you may need to reshape the data first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Input and output data\n",
    "x = chickendata['BUDAPEST'].values.reshape(-1,1)\n",
    "y = chickendata['VAS']\n",
    "\n",
    "# OLS linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(x, y)\n",
    "\n",
    "# Plot the regression line, small dots and black regression line\n",
    "sns.regplot(x='BUDAPEST', y='VAS', data=chickendata, scatter_kws={'s':2}, line_kws={\"color\": \"black\"})\n",
    "\n",
    "# Add more ticks to the x and y axis\n",
    "plt.xticks(range(0, 500+1, 50))\n",
    "plt.yticks(range(0, 150+1, 10))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1.7: What is the value of the coefficient of determination for the linear regression model of Task 1.6?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the R squared value\n",
    "r_squared = model.score(x, y)\n",
    "\n",
    "# Print the R squared value\n",
    "print('R squared:', r_squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1.8: Use Scikit-learn to fit an ordinary least squares linear regression model to predict the values of the BUDAPEST column with all the other data columns of the chickendata dataset, not only with the VAS column. Find the $R^2$-value for the prediction. Similarly, fit a Ridge regression model and also a LASSO regression model to the same data. Find the corresponding $R^2$-values for these two models as you did for the simple linear regression model. That is, you need to print all the three coefficients of determination to pass this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and output data\n",
    "x = chickendata.drop(columns=['Date', 'BUDAPEST'])\n",
    "y = chickendata['BUDAPEST']\n",
    "\n",
    "# OLS linear regression model\n",
    "model2 = LinearRegression()\n",
    "model2.fit(x, y)\n",
    "\n",
    "# R^2 value for the OLS model\n",
    "r_squared_ols = model2.score(x, y)\n",
    "\n",
    "# Ridge regression model\n",
    "model_ridge = Ridge()\n",
    "model_ridge.fit(x, y)\n",
    "\n",
    "# R^2 value for the Ridge model\n",
    "r_squared_ridge = model_ridge.score(x, y)\n",
    "\n",
    "# Lasso regression model\n",
    "model_lasso = Lasso()\n",
    "model_lasso.fit(x, y)\n",
    "\n",
    "# R^2 value for the Lasso model\n",
    "r_squared_lasso = model_lasso.score(x, y)\n",
    "\n",
    "# Print R^2 values\n",
    "print('R^2 (OLS):', r_squared_ols)\n",
    "print('R^2 (Ridge):', r_squared_ridge)\n",
    "print('R^2 (Lasso):', r_squared_lasso)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1.9: Now you have three different models and three different $R^2$-values. In terms of the $R^2$-value, which model performs the best? How would you comment these results in your own words? Enter your answer here:\n",
    "\n",
    "The R squared values/scores from these three models are extremely similar and they were all pretty high scores. The OLS model had slightly higher score than the two other models and can be said to perform the best. Comparing the OLS model score when using all of the columns instead of only VAS increased to score tremendously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Binary classification with logistic regression and Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2.1: Download the DryBeanDataset.zip file from\n",
    "https://archive.ics.uci.edu/ml/datasets/Dry+Bean+Dataset and save Dry_Bean_Dataset.xlsx to variable \"beandata\". You need to read an .xlsx file now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data set and create a data frames\n",
    "beandata = pd.read_excel('Dry_Bean_Dataset.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2.2: Print the beandata dataset by simply writing the variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beandata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2.3: Use the describe() method to describe the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beandata.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2.4: What is the range (the difference between the maximum and the minimum) of the Area feature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(range(beandata['Area'].max(), beandata['Area'].min()))\n",
    "print('Area max value - min value:', (beandata['Area'].max() - beandata['Area'].min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2.5: Use Seaborn to plot the pairplots of the dataset with the hue argument set to the class of the bean. Note that there are several kinds of beans. Follow the link in Task 2.1 if you want to read more details about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot pairpllots hue by class\n",
    "sns.pairplot(beandata, hue='Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2.6: Imagine that you were to use a regression model to predict the Eccentricity feature as the regression target variable with the AspectRation feature as the independent variable. By looking at the corresponding pairplot above, what type of a regression model would you choose? Motivate your answer in your own words.\n",
    "\n",
    "Bonus: If you want, you can also apply the regression model of your choice here and plot the results, but this is not compulsory. Nonetheless, executing this bonus task can compensate for some shortcomings in the other tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2.7: Let's say we are only interested in Bombay beans. Use Scikit-learn to build a logistic regression predictor based on the major axis length of the beans to separate Bombay beans from other beans. Plot the regression curve in the same figure with the corresponding scatterplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2.8: Use the score() method to evaluate the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2.9: How would you describe the accuracy value? Write your answer in your own words here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2.10: Let's say we are still only interested in the Bombay beans of Task 2. Use Scikit-learn to build a Gaussian Naive Bayes (GaussianNB) predictor based on the major axis length of the beans to separate Bombay beans from other beans. Plot the regression curve in the same figure with the corresponding scatterplot. That is, repeat Task 2.7 but this time with the GaussianNB classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2.11: Use the score() method to evaluate the accuracy of the GaussianNB model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2.12: How many beans did the classifier misclassify?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2.13: How would you comment the results in your own words? Compare the logistic regression model and the Gaussian Naive Bayes model performance. Write your answer in your own words here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GIK2FB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "73a4deffa37449eec2906a82541729956dc4ede81d351440dc1e5a408dd292eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
