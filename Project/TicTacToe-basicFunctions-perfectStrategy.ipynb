{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b38161df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for setting up and playing TicTacToe\n",
    "import numpy as numpy\n",
    "import copy\n",
    "import random\n",
    "\n",
    "# Generate an empty board\n",
    "def getEmptyBoard():\n",
    "    return [0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "\n",
    "# Generate a random board, never return a board that can't exist when following the game rules\n",
    "def getRandomBoard():\n",
    "    board = list(numpy.random.choice([0,1,2],(9)))\n",
    "    if board.count(1) - board.count(2) < 0 or board.count(1) - board.count(2) > 1:\n",
    "        return getRandomBoard()\n",
    "    return board\n",
    "\n",
    "\n",
    "# Show the board\n",
    "def showBoard(board):\n",
    "    S=\"\"\n",
    "    T=[\"Â·\",\"O\",\"X\"]\n",
    "    for i in [0,3,6]:\n",
    "        S=S+T[board[i]]+\" \"+T[board[i+1]]+\" \"+T[board[i+2]]\n",
    "        S=S+\"\\n\"\n",
    "    print (S)\n",
    "\n",
    "\n",
    "# Check for winning line\n",
    "def score(board):\n",
    "    line=0\n",
    "    if board[0]==board[1] and board[1]==board[2] and board[0]!=0:\n",
    "        line=board[0]\n",
    "    if board[3]==board[4] and board[4]==board[5] and board[3]!=0:\n",
    "        line=board[3]\n",
    "    if board[6]==board[7] and board[7]==board[8] and board[6]!=0:\n",
    "        line=board[6]\n",
    "        \n",
    "    if board[0]==board[3] and board[3]==board[6] and board[0]!=0:\n",
    "        line=board[0]\n",
    "    if board[1]==board[4] and board[4]==board[7] and board[1]!=0:\n",
    "        line=board[1]\n",
    "    if board[2]==board[5] and board[5]==board[8] and board[2]!=0:\n",
    "        line=board[2]\n",
    "\n",
    "    if board[0]==board[4] and board[4]==board[8] and board[0]!=0:\n",
    "        line=board[0]\n",
    "    if board[2]==board[4] and board[4]==board[6] and board[2]!=0:\n",
    "        line=board[2]  \n",
    "    return line\n",
    "\n",
    "\n",
    "# Check if the game is over\n",
    "def gameOver(board):\n",
    "    s=score(board)\n",
    "    if board.count(0)==0 or s!=0:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# Make a move\n",
    "def doMove(board,move,who):\n",
    "    newBoard=copy.deepcopy(board)\n",
    "    newBoard[move]=who\n",
    "    return newBoard\n",
    "\n",
    "\n",
    "# Get all legal moves\n",
    "def getAllMoves(board):\n",
    "    ret=[]\n",
    "    for i in range(9):\n",
    "        if board[i]==0:\n",
    "            ret.append(i)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b449f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test empty board\n",
    "print(\"Empty board tests:\")\n",
    "testEmptyBoard = getEmptyBoard()\n",
    "print(testEmptyBoard)\n",
    "showBoard(testEmptyBoard)\n",
    "print(\"Score:\",score(testEmptyBoard))\n",
    "\n",
    "# Test random boards\n",
    "noOfTests = 3\n",
    "print(\"\\n%d random board tests:\\n\" % noOfTests)\n",
    "\n",
    "for i in range(noOfTests):\n",
    "    print(\"Run\",i+1)\n",
    "    testRandomBoard = getRandomBoard()\n",
    "    showBoard(testRandomBoard)\n",
    "    print(\"Score:\",score(testRandomBoard),\"\\n\")\n",
    "\n",
    "# Test doMove\n",
    "print(\"\\nTest doMove():\")\n",
    "testDoMove=getEmptyBoard()\n",
    "showBoard(testDoMove)\n",
    "testDoMove=doMove(testDoMove,4,1)\n",
    "showBoard(testDoMove)\n",
    "\n",
    "# Test getAllMoves\n",
    "print(\"\\nTest getAllMoves():\")\n",
    "testGetAllMoves=getRandomBoard()\n",
    "showBoard(testGetAllMoves)\n",
    "print(getAllMoves(testGetAllMoves))\n",
    "\n",
    "# Test gameOver\n",
    "print(\"\\nTest gameOver():\")\n",
    "for i in range(4):\n",
    "    testGameOver=getRandomBoard()\n",
    "    showBoard(testGameOver)\n",
    "    print(gameOver(testGameOver),\"\\n---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bd6c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random strategy function\n",
    "def addPossibleBoards(board,who):\n",
    "    moves=getAllMoves(board)\n",
    "    V=numpy.ones(len(moves))\n",
    "    V=V/V.sum()\n",
    "    if score(board)==0 and list(board).count(0)!=0:\n",
    "        randomStrategy[tuple(board)]=V\n",
    "    flipMove=[0,2,1]\n",
    "    for move in moves:\n",
    "        newBoard=doMove(board,move,who)\n",
    "        addPossibleBoards(newBoard,flipMove[who])\n",
    "\n",
    "\n",
    "# Generate randomStrategy\n",
    "randomStrategy=dict()\n",
    "board=getEmptyBoard()\n",
    "addPossibleBoards(board,1)\n",
    "\n",
    "# Show info about the random strategy\n",
    "print(len(randomStrategy))\n",
    "print(randomStrategy[tuple(getEmptyBoard())])\n",
    "board=[1,1,2,2,1,0,0,0,2]\n",
    "showBoard(board)\n",
    "print(randomStrategy[tuple(board)])\n",
    "\n",
    "# Save the random strategy policy to a file\n",
    "#import pickle\n",
    "#pickle.dump(randomStrategy,open(\"./inClassRandomPolicy.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea873118",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'flipMove' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 63\u001b[0m\n\u001b[1;32m     58\u001b[0m             current_q_values[idx] \u001b[39m=\u001b[39m current_q_values[idx] \u001b[39m+\u001b[39m learning_rate \u001b[39m*\u001b[39m (reward \u001b[39m+\u001b[39m discount_factor \u001b[39m*\u001b[39m next_q_values\u001b[39m.\u001b[39mmax() \u001b[39m-\u001b[39m current_q_values[idx])\n\u001b[1;32m     59\u001b[0m             reinforcementPolicy[\u001b[39mtuple\u001b[39m(board)] \u001b[39m=\u001b[39m current_q_values\n\u001b[0;32m---> 63\u001b[0m q_learning_algorithm(\u001b[39m100\u001b[39;49m)\n\u001b[1;32m     66\u001b[0m \u001b[39m#reinforcementPolicy=dict()\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[39m#board=getEmptyBoard()\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[39m#addPossibleBoardsQLearning(board, 1)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 19\u001b[0m, in \u001b[0;36mq_learning_algorithm\u001b[0;34m(num_games)\u001b[0m\n\u001b[1;32m     17\u001b[0m reinforcementPolicy\u001b[39m=\u001b[39m\u001b[39mdict\u001b[39m()\n\u001b[1;32m     18\u001b[0m board \u001b[39m=\u001b[39m getEmptyBoard()\n\u001b[0;32m---> 19\u001b[0m addPossibleBoardsQLearning(board,\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     20\u001b[0m \u001b[39mfor\u001b[39;00m game \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_games):\n\u001b[1;32m     21\u001b[0m     board \u001b[39m=\u001b[39m getEmptyBoard()\n",
      "Cell \u001b[0;32mIn[8], line 50\u001b[0m, in \u001b[0;36maddPossibleBoardsQLearning\u001b[0;34m(board, who)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[39mfor\u001b[39;00m move \u001b[39min\u001b[39;00m moves:\n\u001b[1;32m     49\u001b[0m         newBoard\u001b[39m=\u001b[39mdoMove(board,move,who)\n\u001b[0;32m---> 50\u001b[0m         addPossibleBoardsQLearning(newBoard,flipMove[who])\n\u001b[1;32m     51\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m     \u001b[39m# Update Q-values using Q-learning update rule\u001b[39;00m\n\u001b[1;32m     53\u001b[0m     current_q_values \u001b[39m=\u001b[39m reinforcementPolicy[\u001b[39mtuple\u001b[39m(board)]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'flipMove' is not defined"
     ]
    }
   ],
   "source": [
    "# Take action and get next state, reward, and game status\n",
    "def takeAction(board, action, who):\n",
    "    next_board = doMove(board, action, who)\n",
    "    if gameOver(next_board):\n",
    "        reward = score(next_board)\n",
    "        return next_board, reward, True\n",
    "    reward = 0\n",
    "    return next_board, reward, False\n",
    "\n",
    "\n",
    "def q_learning_algorithm(num_games):\n",
    "    # Hyperparameters\n",
    "    learning_rate = 0.1\n",
    "    discount_factor = 0.9\n",
    "    exploration_rate = 0.1\n",
    "    flipMove=[0,2,1]\n",
    "    reinforcementPolicy=dict()\n",
    "    board = getEmptyBoard()\n",
    "    addPossibleBoardsQLearning(board,1)\n",
    "    for game in range(num_games):\n",
    "        board = getEmptyBoard()\n",
    "        done = False\n",
    "        who = 1\n",
    "        while not done:\n",
    "            moves=getAllMoves(board)\n",
    "            if random.uniform(0, 1) < exploration_rate:\n",
    "                action = random.choice(moves)\n",
    "            else:\n",
    "                q_values = reinforcementPolicy[tuple(board)]\n",
    "                action = moves[q_values.argmax()]\n",
    "            next_board, reward, done = takeAction(board, action, who)\n",
    "            next_q_values = reinforcementPolicy[tuple(next_board)]\n",
    "            current_q_values = reinforcementPolicy[tuple(board)][action]\n",
    "            reinforcementPolicy[tuple(board)][action] = current_q_values + learning_rate * (reward + discount_factor * next_q_values.max() - current_q_values)\n",
    "            board = next_board\n",
    "            who = flipMove[who]\n",
    "    print(\"Training done!\")\n",
    "\n",
    "\"\"\" \n",
    "# Generate Q-learning policy\n",
    "def addPossibleBoardsQLearning(board,who):\n",
    "    moves=getAllMoves(board)\n",
    "    if tuple(board) not in reinforcementPolicy:\n",
    "        # Initialize Q-values for each state-action pair\n",
    "        q_values = numpy.zeros(len(moves))\n",
    "        reinforcementPolicy[tuple(board)] = q_values\n",
    "    if score(board)==0 and list(board).count(0)!=0:\n",
    "        for move in moves:\n",
    "            newBoard=doMove(board,move,who)\n",
    "            addPossibleBoardsQLearning(newBoard,flipMove[who])\n",
    "    else:\n",
    "        # Update Q-values using Q-learning update rule\n",
    "        current_q_values = reinforcementPolicy[tuple(board)]\n",
    "        for idx, move in enumerate(moves):\n",
    "            newBoard=doMove(board,move,who)\n",
    "            next_q_values = reinforcementPolicy[tuple(newBoard)]\n",
    "            reward = score(newBoard)\n",
    "            current_q_values[idx] = current_q_values[idx] + learning_rate * (reward + discount_factor * next_q_values.max() - current_q_values[idx])\n",
    "            reinforcementPolicy[tuple(board)] = current_q_values\n",
    " \"\"\"\n",
    "\n",
    "\n",
    "q_learning_algorithm(100)\n",
    "\n",
    "\n",
    "#reinforcementPolicy=dict()\n",
    "#board=getEmptyBoard()\n",
    "#addPossibleBoardsQLearning(board, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "392f3587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomPolicy length: 4520\n",
      "perfectPolicy length: 4520\n"
     ]
    }
   ],
   "source": [
    "# Load policies from files\n",
    "import pickle\n",
    "randomPolicy=pickle.load(open(\"./inClassRandomPolicy.p\",\"rb\"))\n",
    "print(\"randomPolicy length:\", len(randomPolicy))\n",
    "perfectPolicy=pickle.load(open(\"./perfectPolicy.p\",\"rb\"))\n",
    "print(\"perfectPolicy length:\", len(perfectPolicy))\n",
    "#reinforcementPolicy=pickle.load(open(\"./reinforcementPolicy.p\",\"rb\"))\n",
    "#print(\"reinforcementPolicy length:\", len(perfectPolicy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff420654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discover policy files\n",
    "\n",
    "## Perfect policy\n",
    "\n",
    "#print(perfectPolicy)\n",
    "#print(list(perfectPolicy.keys()))\n",
    "\n",
    "# Test perfect policy\n",
    "#for i in range(10):\n",
    "#    keys=list(perfectPolicy.keys())\n",
    "#    which=numpy.random.randint(0,4520)\n",
    "#    board=keys[which]\n",
    "#    showBoard(board)\n",
    "#    print(perfectPolicy[board])\n",
    "#    print(\"---\")\n",
    "\n",
    "## Random policy\n",
    "\n",
    "#print(randomPolicy)\n",
    "#print(list(randomPolicy.keys()))\n",
    "\n",
    "# Test perfect policy\n",
    "for i in range(10):\n",
    "    keys=list(perfectPolicy.keys())\n",
    "    which=numpy.random.randint(0,4520)\n",
    "    board=keys[which]\n",
    "    showBoard(board)\n",
    "    print(perfectPolicy[board])\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af1950c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test perfect policy\n",
    "for i in range(10):\n",
    "    keys=list(perfectPolicy.keys())\n",
    "    which=numpy.random.randint(0,4520)\n",
    "    board=keys[which]\n",
    "    showBoard(board)\n",
    "    print(perfectPolicy[board])\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b74a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for testing policies against eachother\n",
    "\n",
    "# Play a game between two policies\n",
    "def playTwoPolicies(policyA,policyB,verbose=False):\n",
    "    flipMove=[0,2,1]\n",
    "    who=1\n",
    "    board=[0,0,0,0,0,0,0,0,0]\n",
    "    done=False\n",
    "    while not done:\n",
    "        if verbose:\n",
    "            showBoard(board)\n",
    "        moves=getAllMoves(board)\n",
    "        if who==1:\n",
    "            p=policyA[tuple(board)]\n",
    "        else:\n",
    "            p=policyB[tuple(board)]\n",
    "        if verbose:\n",
    "            print(p)\n",
    "        p/=p.sum()\n",
    "        choice=numpy.random.choice(moves,p=p)\n",
    "        board=doMove(board,choice,who)\n",
    "        s=score(board)\n",
    "        if len(moves)==1 or s!=0:\n",
    "            done=True\n",
    "        who=flipMove[who]\n",
    "    if verbose:\n",
    "        showBoard(board)\n",
    "    if s==0:\n",
    "        return 0\n",
    "    return flipMove[who]\n",
    "\n",
    "\n",
    "# Sample games between two policies\n",
    "def sampleGames(policyA,policyB,nrOfGames=100):\n",
    "    result=[0,0,0]\n",
    "    for n in range(nrOfGames):\n",
    "        winner=playTwoPolicies(policyA,policyB)\n",
    "        result[winner]+=1\n",
    "    result=numpy.array(result)\n",
    "    return result/result.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a99fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play a game between two policies\n",
    "playTwoPolicies(randomPolicy,randomPolicy,verbose=False)\n",
    "\n",
    "# Sample games between policies\n",
    "print(\"randomPolicy vs randomPolicy\",sampleGames(randomPolicy,randomPolicy,nrOfGames=100000))\n",
    "print(\"perfectPolicy vs perfectPolicy\",sampleGames(perfectPolicy,perfectPolicy,nrOfGames=100000))\n",
    "print(\"perfectPolicy vs randomPolicy\",sampleGames(perfectPolicy,randomPolicy,nrOfGames=100000))\n",
    "print(\"randomPolicy vs perfectPolicy\",sampleGames(randomPolicy,perfectPolicy,nrOfGames=100000))\n",
    "#print(\"reinforcementPolicy vs reinforcementPolicy\",sampleGames(reinforcementPolicy,reinforcementPolicy,nrOfGames=100000))\n",
    "#print(\"reinforcementPolicy vs randomPolicy\",sampleGames(reinforcementPolicy,randomPolicy,nrOfGames=100000))\n",
    "#print(\"reinforcementPolicy vs perfectPolicy\",sampleGames(reinforcementPolicy,perfectPolicy,nrOfGames=100000))\n",
    "#print(\"randomPolicy vs reinforcementPolicy\",sampleGames(randomPolicy,reinforcementPolicy,nrOfGames=100000))\n",
    "#print(\"perfectPolicy vs reinforcementPolicy\",sampleGames(perfectPolicy,reinforcementPolicy,nrOfGames=100000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GIK2FB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "73a4deffa37449eec2906a82541729956dc4ede81d351440dc1e5a408dd292eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
