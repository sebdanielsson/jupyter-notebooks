{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38161df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for setting up and playing TicTacToe\n",
    "import numpy as numpy\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "# Generate an empty board\n",
    "def getEmptyBoard():\n",
    "    return [0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "\n",
    "# Generate a random board, never return a board that can't exist when following the game rules\n",
    "def getRandomBoard():\n",
    "    board = list(numpy.random.choice([0,1,2],(9)))\n",
    "    if board.count(1) - board.count(2) < 0 or board.count(1) - board.count(2) > 1:\n",
    "        return getRandomBoard()\n",
    "    return board\n",
    "\n",
    "\n",
    "# Show the board\n",
    "def showBoard(board):\n",
    "    S=\"\"\n",
    "    T=[\"Â·\",\"O\",\"X\"]\n",
    "    for i in [0,3,6]:\n",
    "        S=S+T[board[i]]+\" \"+T[board[i+1]]+\" \"+T[board[i+2]]\n",
    "        S=S+\"\\n\"\n",
    "    print (S)\n",
    "\n",
    "\n",
    "# Check for winning line\n",
    "def score(board):\n",
    "    line=0\n",
    "    if board[0]==board[1] and board[1]==board[2] and board[0]!=0:\n",
    "        line=board[0]\n",
    "    if board[3]==board[4] and board[4]==board[5] and board[3]!=0:\n",
    "        line=board[3]\n",
    "    if board[6]==board[7] and board[7]==board[8] and board[6]!=0:\n",
    "        line=board[6]\n",
    "        \n",
    "    if board[0]==board[3] and board[3]==board[6] and board[0]!=0:\n",
    "        line=board[0]\n",
    "    if board[1]==board[4] and board[4]==board[7] and board[1]!=0:\n",
    "        line=board[1]\n",
    "    if board[2]==board[5] and board[5]==board[8] and board[2]!=0:\n",
    "        line=board[2]\n",
    "\n",
    "    if board[0]==board[4] and board[4]==board[8] and board[0]!=0:\n",
    "        line=board[0]\n",
    "    if board[2]==board[4] and board[4]==board[6] and board[2]!=0:\n",
    "        line=board[2]  \n",
    "    return line\n",
    "\n",
    "\n",
    "# Check if the game is over\n",
    "def gameOver(board):\n",
    "    s=score(board)\n",
    "    if board.count(0)==0 or s!=0:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# Make a move\n",
    "def doMove(board,move,who):\n",
    "    newBoard=copy.deepcopy(board)\n",
    "    newBoard[move]=who\n",
    "    return newBoard\n",
    "\n",
    "\n",
    "# Get all legal moves\n",
    "def getAllMoves(board):\n",
    "    ret=[]\n",
    "    for i in range(9):\n",
    "        if board[i]==0:\n",
    "            ret.append(i)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b449f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test empty board\n",
    "print(\"Empty board tests:\")\n",
    "testEmptyBoard = getEmptyBoard()\n",
    "print(testEmptyBoard)\n",
    "showBoard(testEmptyBoard)\n",
    "print(\"Score:\",score(testEmptyBoard))\n",
    "\n",
    "# Test random boards\n",
    "noOfTests = 3\n",
    "print(\"\\n%d random board tests:\\n\" % noOfTests)\n",
    "\n",
    "for i in range(noOfTests):\n",
    "    print(\"Run\",i+1)\n",
    "    testRandomBoard = getRandomBoard()\n",
    "    showBoard(testRandomBoard)\n",
    "    print(\"Score:\",score(testRandomBoard),\"\\n\")\n",
    "\n",
    "# Test doMove\n",
    "print(\"\\nTest doMove():\")\n",
    "testDoMove=getEmptyBoard()\n",
    "showBoard(testDoMove)\n",
    "testDoMove=doMove(testDoMove,4,1)\n",
    "showBoard(testDoMove)\n",
    "\n",
    "# Test getAllMoves\n",
    "print(\"\\nTest getAllMoves():\")\n",
    "testGetAllMoves=getRandomBoard()\n",
    "showBoard(testGetAllMoves)\n",
    "print(getAllMoves(testGetAllMoves))\n",
    "\n",
    "# Test gameOver\n",
    "print(\"\\nTest gameOver():\")\n",
    "for i in range(4):\n",
    "    testGameOver=getRandomBoard()\n",
    "    showBoard(testGameOver)\n",
    "    print(gameOver(testGameOver),\"\\n---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bd6c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random strategy function\n",
    "def addPossibleBoards(board,who):\n",
    "    moves=getAllMoves(board)\n",
    "    V=numpy.ones(len(moves))\n",
    "    V=V/V.sum()\n",
    "    if score(board)==0 and list(board).count(0)!=0:\n",
    "        randomStrategy[tuple(board)]=V\n",
    "    flipMove=[0,2,1]\n",
    "    for move in moves:\n",
    "        newBoard=doMove(board,move,who)\n",
    "        addPossibleBoards(newBoard,flipMove[who])\n",
    "\n",
    "\n",
    "# Generate randomStrategy\n",
    "randomStrategy=dict()\n",
    "board=getEmptyBoard()\n",
    "addPossibleBoards(board,1)\n",
    "\n",
    "# Save randomStrategy to a file\n",
    "pickle.dump(randomStrategy,open(\"./inClassRandomPolicy.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea873118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Q-table with some initial values\n",
    "# The keys are tuples representing the states and the values are arrays of size 9 representing the Q-values for each possible move\n",
    "# in that state\n",
    "Q = dict()\n",
    "\n",
    "# Define the learning rate and the discount factor\n",
    "alpha = 0.1\n",
    "gamma = 0.9\n",
    "\n",
    "# Define the exploration policy, such as epsilon-greedy\n",
    "epsilon = 0.1\n",
    "\n",
    "# Define the number of episodes to train the policy\n",
    "num_episodes = 100000\n",
    "\n",
    "# flipMove is used to switch between players\n",
    "flipMove=[0,2,1]\n",
    "\n",
    "# Define who starts the game\n",
    "who = 1\n",
    "\n",
    "# Define a function to get the Q-value for a given state and action\n",
    "def getQ(state, action):\n",
    "    if tuple(state) not in Q:\n",
    "        Q[tuple(state)] = numpy.zeros(9)\n",
    "    return Q[tuple(state)][action]\n",
    "\n",
    "# Define a function to update the Q-value for a given state and action\n",
    "def updateQ(state, action, value):\n",
    "    if tuple(state) not in Q:\n",
    "        Q[tuple(state)] = numpy.zeros(9)\n",
    "    Q[tuple(state)][action] = value\n",
    "\n",
    "# Train the Q-learning policy\n",
    "for i in range(num_episodes):\n",
    "    # Start a new game\n",
    "    board = getEmptyBoard()\n",
    "\n",
    "    while not gameOver(board):\n",
    "        # Select the next action using the exploration policy\n",
    "        moves = getAllMoves(board)\n",
    "        if numpy.random.uniform(0, 1) < epsilon:\n",
    "            # Choose a random move with probability epsilon\n",
    "            action = numpy.random.choice(moves)\n",
    "        else:\n",
    "            # Choose the move with the highest Q-value with probability 1 - epsilon\n",
    "            action = numpy.argmax([getQ(board, move) for move in moves])\n",
    "\n",
    "        # Make the selected move\n",
    "        next_board = doMove(board, action, who)\n",
    "\n",
    "        # Update the Q-value for the current state and action\n",
    "        reward = score(next_board)\n",
    "        if gameOver(next_board):\n",
    "            updateQ(board, action, reward)\n",
    "        else:\n",
    "            next_moves = getAllMoves(next_board)\n",
    "            updateQ(board, action, (1 - alpha) * getQ(board, action) + alpha * (reward + gamma * max([getQ(next_board, next_move) for next_move in next_moves])))\n",
    "        \n",
    "        board = next_board\n",
    "        who = flipMove[who]\n",
    "\n",
    "# Save the Q-table policy to a file\n",
    "QlearningStrategy = Q\n",
    "\n",
    "\"\"\" # Function to convert Q-values to a probability distribution (SOFTMAX)\n",
    "def q_to_prob(q_values, legal_moves):\n",
    "    prob = numpy.zeros(len(q_values))\n",
    "    prob[legal_moves] = numpy.exp(q_values[legal_moves])\n",
    "    prob[legal_moves] /= prob[legal_moves].sum()\n",
    "    return prob \"\"\"\n",
    "\n",
    "# Function to convert Q-values to a probability distribution\n",
    "def q_to_prob(q_values,legal_moves):\n",
    "    prob = numpy.zeros(len(legal_moves))\n",
    "    best_action = numpy.argmax(q_values[legal_moves])\n",
    "    prob[best_action] = 1\n",
    "    return prob\n",
    "\n",
    "\n",
    "# Create a new dictionary to store the Q-learning policy as a probability distribution\n",
    "ql_policy = {}\n",
    "for state in QlearningStrategy:\n",
    "    legal_moves = getAllMoves(list(state))\n",
    "    q_values = QlearningStrategy[state]\n",
    "    ql_policy[state] = q_to_prob(q_values, legal_moves)\n",
    "\n",
    "# Save QlearningStrategy to a file\n",
    "#pickle.dump(QlearningStrategy,open(\"./QlearningStrategy.p\",\"wb\"))\n",
    "#pickle.dump(ql_policy,open(\"./ql_policy.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f55778",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(QlearningStrategy))\n",
    "print(QlearningStrategy[tuple(getEmptyBoard())])\n",
    "board=[1,1,2,2,1,0,0,0,2]\n",
    "showBoard(board)\n",
    "print(QlearningStrategy[tuple(board)])\n",
    "\n",
    "print(len(ql_policy))\n",
    "print(ql_policy[tuple(getEmptyBoard())])\n",
    "board=[1,1,2,2,1,0,0,0,2]\n",
    "showBoard(board)\n",
    "print(ql_policy[tuple(board)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392f3587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load policies from files\n",
    "import pickle\n",
    "randomPolicy=pickle.load(open(\"./inClassRandomPolicy.p\",\"rb\"))\n",
    "print(\"randomPolicy length:\", len(randomPolicy))\n",
    "perfectPolicy=pickle.load(open(\"./perfectPolicy.p\",\"rb\"))\n",
    "print(\"perfectPolicy length:\", len(perfectPolicy))\n",
    "#QlearningStrategy=pickle.load(open(\"./QlearningStrategy.p\",\"rb\"))\n",
    "#ql_policy=pickle.load(open(\"./ql_policy.p\",\"rb\"))\n",
    "print(\"QlearningStrategy length:\", len(QlearningStrategy))\n",
    "print(\"ql_policy length:\", len(ql_policy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b74a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for testing policies against eachother\n",
    "\n",
    "# Play a game between two policies\n",
    "def playTwoPolicies(policyA,policyB,verbose=False):\n",
    "    flipMove=[0,2,1]\n",
    "    who=1\n",
    "    board=[0,0,0,0,0,0,0,0,0]\n",
    "    done=False\n",
    "    while not done:\n",
    "        if verbose:\n",
    "            showBoard(board)\n",
    "        moves=getAllMoves(board)\n",
    "        if who==1:\n",
    "            p=policyA[tuple(board)]\n",
    "        else:\n",
    "            p=policyB[tuple(board)]\n",
    "        if verbose:\n",
    "            print(p,\"\\n---\")\n",
    "        p/=p.sum()\n",
    "        choice=numpy.random.choice(moves,p=p)\n",
    "        board=doMove(board,choice,who)\n",
    "        s=score(board)\n",
    "        if len(moves)==1 or s!=0:\n",
    "            done=True\n",
    "        who=flipMove[who]\n",
    "    if verbose:\n",
    "        showBoard(board)\n",
    "    if s==0:\n",
    "        return 0\n",
    "    return flipMove[who]\n",
    "\n",
    "\n",
    "# Sample games between two policies\n",
    "def sampleGames(policyA, policyB, nrOfGames=100):\n",
    "    result = [0, 0, 0]\n",
    "    for _ in range(nrOfGames):\n",
    "        winner = playTwoPolicies(policyA, policyB)\n",
    "        if winner == 0:\n",
    "            result[0] += 1\n",
    "        elif winner == 1:\n",
    "            result[1] += 1\n",
    "        else:\n",
    "            result[2] += 1\n",
    "    result = numpy.array(result)\n",
    "    return result / result.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a99fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmarking\n",
    "\n",
    "# Play a game between two policies\n",
    "#playTwoPolicies(randomPolicy,randomPolicy,verbose=False)\n",
    "#playTwoPolicies(randomPolicy,perfectPolicy,verbose=False)\n",
    "#playTwoPolicies(randomPolicy,ql_policy,verbose=False)\n",
    "#playTwoPolicies(perfectPolicy,perfectPolicy,verbose=False)\n",
    "#playTwoPolicies(perfectPolicy,randomPolicy,verbose=False)\n",
    "#playTwoPolicies(perfectPolicy,ql_policy,verbose=False)\n",
    "#playTwoPolicies(ql_policy,ql_policy,verbose=False)\n",
    "#playTwoPolicies(ql_policy,perfectPolicy,verbose=False)\n",
    "#playTwoPolicies(ql_policy,randomPolicy,verbose=False)\n",
    "\n",
    "# Sample games between policies\n",
    "print(\"randomPolicy vs randomPolicy [draw, win, lose]\",sampleGames(randomPolicy,randomPolicy,nrOfGames=100000))\n",
    "print(\"randomPolicy vs perfectPolicy [draw, win, lose]\",sampleGames(randomPolicy,perfectPolicy,nrOfGames=100000))\n",
    "print(\"randomPolicy vs ql_policy [draw, win, lose]\",sampleGames(randomPolicy,ql_policy,nrOfGames=100000))\n",
    "print(\"perfectPolicy vs perfectPolicy [draw, win, lose]\",sampleGames(perfectPolicy,perfectPolicy,nrOfGames=100000))\n",
    "print(\"perfectPolicy vs randomPolicy [draw, win, lose]\",sampleGames(perfectPolicy,randomPolicy,nrOfGames=100000))\n",
    "print(\"perfectPolicy vs ql_policy [draw, win, lose]\",sampleGames(perfectPolicy,ql_policy,nrOfGames=100000))\n",
    "print(\"ql_policy vs ql_policy [draw, win, lose]\",sampleGames(ql_policy,ql_policy,nrOfGames=100000))\n",
    "print(\"ql_policy vs randomPolicy [draw, win, lose]\",sampleGames(ql_policy,randomPolicy,nrOfGames=100000))\n",
    "print(\"ql_policy vs perfectPolicy [draw, win, lose]\",sampleGames(ql_policy,perfectPolicy,nrOfGames=100000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8823feff",
   "metadata": {},
   "outputs": [],
   "source": [
    "board=[1,1,2,2,1,0,0,0,2]\n",
    "showBoard(board)\n",
    "print(ql_policy[tuple(board)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b18a6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "board=[1, 0, 1, 0, 1, 2, 0, 2, 2]\n",
    "showBoard(board)\n",
    "print(ql_policy[tuple(board)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GIK2FB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "73a4deffa37449eec2906a82541729956dc4ede81d351440dc1e5a408dd292eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
